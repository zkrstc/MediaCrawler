# å£°æ˜ï¼šæœ¬ä»£ç ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ç›®çš„ä½¿ç”¨ã€‚ä½¿ç”¨è€…åº”éµå®ˆä»¥ä¸‹åŸåˆ™ï¼š
# 1. ä¸å¾—ç”¨äºä»»ä½•å•†ä¸šç”¨é€”ã€‚
# 2. ä½¿ç”¨æ—¶åº”éµå®ˆç›®æ ‡å¹³å°çš„ä½¿ç”¨æ¡æ¬¾å’Œrobots.txtè§„åˆ™ã€‚
# 3. ä¸å¾—è¿›è¡Œå¤§è§„æ¨¡çˆ¬å–æˆ–å¯¹å¹³å°é€ æˆè¿è¥å¹²æ‰°ã€‚
# 4. åº”åˆç†æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¿å…ç»™ç›®æ ‡å¹³å°å¸¦æ¥ä¸å¿…è¦çš„è´Ÿæ‹…ã€‚
# 5. ä¸å¾—ç”¨äºä»»ä½•éæ³•æˆ–ä¸å½“çš„ç”¨é€”ã€‚
#
# è¯¦ç»†è®¸å¯æ¡æ¬¾è¯·å‚é˜…é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„LICENSEæ–‡ä»¶ã€‚
# ä½¿ç”¨æœ¬ä»£ç å³è¡¨ç¤ºæ‚¨åŒæ„éµå®ˆä¸Šè¿°åŸåˆ™å’ŒLICENSEä¸­çš„æ‰€æœ‰æ¡æ¬¾ã€‚

import asyncio
import json
import os
import time
import re
from typing import Any, Callable, Dict, List, Optional, Union
from urllib.parse import urlencode

import httpx
from playwright.async_api import BrowserContext, Page
from tenacity import retry, stop_after_attempt, wait_fixed
from PIL import Image

import config
from base.base_crawler import AbstractApiClient
from tools import utils

from .exception import DataFetchError, IPBlockError
from .field import SearchNoteType, SearchSortType
from .help import get_search_id, sign
from .extractor import XiaoHongShuExtractor
from .secsign import seccore_signv2_playwright

class XiaoHongShuClient(AbstractApiClient):

    def __init__(
        self,
        timeout=60,  # è‹¥å¼€å¯çˆ¬å–åª’ä½“é€‰é¡¹ï¼Œxhs çš„é•¿è§†é¢‘éœ€è¦æ›´ä¹…çš„è¶…æ—¶æ—¶é—´
        proxy=None,
        *,
        headers: Dict[str, str],
        playwright_page: Page,
        cookie_dict: Dict[str, str],
    ):
        self.proxy = proxy
        self.timeout = timeout
        self.headers = headers
        self._host = "https://edith.xiaohongshu.com"
        self._domain = "https://www.xiaohongshu.com"
        self.IP_ERROR_STR = "ç½‘ç»œè¿æ¥å¼‚å¸¸ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–é‡å¯è¯•è¯•"
        self.IP_ERROR_CODE = 300012
        self.NOTE_ABNORMAL_STR = "ç¬”è®°çŠ¶æ€å¼‚å¸¸ï¼Œè¯·ç¨åæŸ¥çœ‹"
        self.NOTE_ABNORMAL_CODE = -510001
        self.playwright_page = playwright_page
        self.cookie_dict = cookie_dict
        self._extractor = XiaoHongShuExtractor()
        self.ip_proxy_pool = None  # Will be set by crawler
        self.cookie_pool_manager = None  # Will be set by crawler

    async def _pre_headers(self, url: str, data=None) -> Dict:
        """
        è¯·æ±‚å¤´å‚æ•°ç­¾å
        Args:
            url:
            data:

        Returns:

        """
        # Wait for window._webmsxyw to be available
        try:
            await self.playwright_page.wait_for_function(
                "typeof window._webmsxyw === 'function'",
                timeout=10000
            )
        except Exception as e:
            utils.logger.error(f"[XiaoHongShuClient._pre_headers] window._webmsxyw not available: {e}")
            # Try to reload the page if the function is not available
            utils.logger.info("[XiaoHongShuClient._pre_headers] Reloading page to initialize window._webmsxyw")
            await self.playwright_page.reload(wait_until="networkidle")
            await self.playwright_page.wait_for_function(
                "typeof window._webmsxyw === 'function'",
                timeout=10000
            )
        
        x_s = await seccore_signv2_playwright(self.playwright_page, url, data)
        local_storage = await self.playwright_page.evaluate("() => window.localStorage")
        signs = sign(
            a1=self.cookie_dict.get("a1", ""),
            b1=local_storage.get("b1", ""),
            x_s=x_s,
            x_t=str(int(time.time())),
        )

        headers = {
            "X-S": signs["x-s"],
            "X-T": signs["x-t"],
            "x-S-Common": signs["x-s-common"],
            "X-B3-Traceid": signs["x-b3-traceid"],
        }
        self.headers.update(headers)
        return self.headers

    async def update_proxy(self, new_proxy: str):
        """
        æ›´æ–°ä»£ç†IP
        Args:
            new_proxy: æ–°çš„ä»£ç†åœ°å€
        """
        self.proxy = new_proxy
        utils.logger.info(f"[XiaoHongShuClient.update_proxy] Proxy updated to: {new_proxy}")

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(1))
    async def request(self, method, url, **kwargs) -> Union[str, Any]:
        """
        å°è£…httpxçš„å…¬å…±è¯·æ±‚æ–¹æ³•ï¼Œå¯¹è¯·æ±‚å“åº”åšä¸€äº›å¤„ç†
        Args:
            method: è¯·æ±‚æ–¹æ³•
            url: è¯·æ±‚çš„URL
            **kwargs: å…¶ä»–è¯·æ±‚å‚æ•°ï¼Œä¾‹å¦‚è¯·æ±‚å¤´ã€è¯·æ±‚ä½“ç­‰

        Returns:

        """
        # return response.text
        return_response = kwargs.pop("return_response", False)
        
        try:
            async with httpx.AsyncClient(proxy=self.proxy) as client:
                response = await client.request(method, url, timeout=self.timeout, **kwargs)
        except httpx.ProxyError as e:
            error_msg = str(e)
            utils.logger.error(f"[XiaoHongShuClient.request] Proxy error: {error_msg}")
            
            # æ£€æµ‹æ˜¯å¦æ˜¯ä»£ç†è®¤è¯å¤±è´¥ï¼ˆ460é”™è¯¯æˆ–Authentication Invalidï¼‰
            if "460" in error_msg or "Proxy Authentication Invalid" in error_msg or "Authentication Invalid" in error_msg:
                utils.logger.warning("[XiaoHongShuClient.request] Proxy authentication failed, attempting to switch proxy...")
                
                # å°è¯•åˆ‡æ¢ä»£ç†
                if self.ip_proxy_pool:
                    try:
                        new_ip_info = await self.ip_proxy_pool.get_proxy()
                        from tools import utils as tool_utils
                        _, new_httpx_proxy = tool_utils.format_proxy_info(new_ip_info)
                        await self.update_proxy(new_httpx_proxy)
                        utils.logger.info(f"[XiaoHongShuClient.request] Switched to new proxy: {new_ip_info.ip}:{new_ip_info.port}")
                        
                        # é‡è¯•è¯·æ±‚
                        async with httpx.AsyncClient(proxy=self.proxy) as client:
                            response = await client.request(method, url, timeout=self.timeout, **kwargs)
                    except Exception as switch_error:
                        utils.logger.error(f"[XiaoHongShuClient.request] Failed to switch proxy: {switch_error}")
                        raise
                else:
                    utils.logger.error("[XiaoHongShuClient.request] No proxy pool available for switching")
                    raise
            else:
                raise

        if response.status_code == 471 or response.status_code == 461:
            # éªŒè¯ç é”™è¯¯ï¼Œå°è¯•åˆ‡æ¢Cookieå’ŒIP
            verify_type = response.headers.get("Verifytype", "unknown")
            verify_uuid = response.headers.get("Verifyuuid", "unknown")
            msg = f"å‡ºç°éªŒè¯ç ï¼Œè¯·æ±‚å¤±è´¥ï¼ŒVerifytype: {verify_type}ï¼ŒVerifyuuid: {verify_uuid}, Response: {response}"
            utils.logger.error(msg)
            
            # åˆ›å»ºè‡ªå®šä¹‰å¼‚å¸¸ç”¨äºæ ‡è¯†éªŒè¯ç é”™è¯¯
            from .exception import CaptchaError
            raise CaptchaError(msg, verify_type=verify_type, verify_uuid=verify_uuid)

        if return_response:
            return response.text
        data: Dict = response.json()
        if data.get("success"):
            return data.get("data", data.get("success", {}))
        elif data.get("code") == self.IP_ERROR_CODE:
            raise IPBlockError(self.IP_ERROR_STR)
        elif data.get("code") in [-100, -101, -102, -104]:
            # Cookie/permission related errors - trigger cookie switching
            # -100: ç™»å½•å·²è¿‡æœŸ (Login expired)
            # -101: æœªç™»å½• (Not logged in)
            # -102: ç™»å½•çŠ¶æ€å¤±æ•ˆ (Login state invalid)
            # -104: è´¦å·æ²¡æœ‰æƒé™è®¿é—® (Account has no permission)
            error_msg = data.get("msg", "Cookie/Permission error")
            utils.logger.error(f"[XiaoHongShuClient.request] Cookie/Permission error (code: {data.get('code')}) - URL: {url}, Response: {data}")
            
            # Import and raise CookieBlockedException to trigger automatic cookie switching
            from tools.cookie_guard import CookieBlockedException
            raise CookieBlockedException(error_msg)
        else:
            # Log the full response for debugging
            error_msg = data.get("msg") or data.get("message") or f"Request failed with response: {data}"
            utils.logger.error(f"[XiaoHongShuClient.request] API request failed - URL: {url}, Response: {data}")
            raise DataFetchError(error_msg)

    async def get(self, uri: str, params=None) -> Dict:
        """
        GETè¯·æ±‚ï¼Œå¯¹è¯·æ±‚å¤´ç­¾å
        Args:
            uri: è¯·æ±‚è·¯ç”±
            params: è¯·æ±‚å‚æ•°

        Returns:

        """
        final_uri = uri
        if isinstance(params, dict):
            final_uri = f"{uri}?" f"{urlencode(params)}"
        headers = await self._pre_headers(final_uri)
        return await self.request(
            method="GET", url=f"{self._host}{final_uri}", headers=headers
        )

    async def post(self, uri: str, data: dict, **kwargs) -> Dict:
        """
        POSTè¯·æ±‚ï¼Œå¯¹è¯·æ±‚å¤´ç­¾å
        Args:
            uri: è¯·æ±‚è·¯ç”±
            data: è¯·æ±‚ä½“å‚æ•°

        Returns:

        """
        headers = await self._pre_headers(uri, data)
        json_str = json.dumps(data, separators=(",", ":"), ensure_ascii=False)
        return await self.request(
            method="POST",
            url=f"{self._host}{uri}",
            data=json_str,
            headers=headers,
            **kwargs,
        )

    async def get_note_media(self, url: str) -> Union[bytes, None]:
        async with httpx.AsyncClient(proxy=self.proxy) as client:
            try:
                response = await client.request("GET", url, timeout=self.timeout)
                response.raise_for_status()
                if not response.reason_phrase == "OK":
                    utils.logger.error(
                        f"[XiaoHongShuClient.get_note_media] request {url} err, res:{response.text}"
                    )
                    return None
                else:
                    return response.content
            except (
                httpx.HTTPError
            ) as exc:  # some wrong when call httpx.request method, such as connection error, client error, server error or response status code is not 2xx
                utils.logger.error(
                    f"[XiaoHongShuClient.get_aweme_media] {exc.__class__.__name__} for {exc.request.url} - {exc}"
                )  # ä¿ç•™åŸå§‹å¼‚å¸¸ç±»å‹åç§°ï¼Œä»¥ä¾¿å¼€å‘è€…è°ƒè¯•
                return None

    async def pong(self) -> bool:
        """
        ç”¨äºæ£€æŸ¥ç™»å½•æ€æ˜¯å¦å¤±æ•ˆäº†
        Returns:

        """
        """get a note to check if login state is ok"""
        utils.logger.info("[XiaoHongShuClient.pong] Begin to pong xhs...")
        ping_flag = False
        try:
            note_card: Dict = await self.get_note_by_keyword(keyword="å°çº¢ä¹¦")
            if note_card.get("items"):
                ping_flag = True
        except Exception as e:
            utils.logger.error(
                f"[XiaoHongShuClient.pong] Ping xhs failed: {e}, and try to login again..."
            )
            ping_flag = False
        return ping_flag

    async def update_cookies(self, browser_context: BrowserContext):
        """
        APIå®¢æˆ·ç«¯æä¾›çš„æ›´æ–°cookiesæ–¹æ³•ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ç™»å½•æˆåŠŸåä¼šè°ƒç”¨æ­¤æ–¹æ³•
        Args:
            browser_context: æµè§ˆå™¨ä¸Šä¸‹æ–‡å¯¹è±¡

        Returns:

        """
        cookie_str, cookie_dict = utils.convert_cookies(await browser_context.cookies())
        self.headers["Cookie"] = cookie_str
        self.cookie_dict = cookie_dict

    async def get_note_by_keyword(
        self,
        keyword: str,
        search_id: str = get_search_id(),
        page: int = 1,
        page_size: int = 20,
        sort: SearchSortType = SearchSortType.GENERAL,
        note_type: SearchNoteType = SearchNoteType.ALL,
    ) -> Dict:
        """
        æ ¹æ®å…³é”®è¯æœç´¢ç¬”è®°
        Args:
            keyword: å…³é”®è¯å‚æ•°
            page: åˆ†é¡µç¬¬å‡ é¡µ
            page_size: åˆ†é¡µæ•°æ®é•¿åº¦
            sort: æœç´¢ç»“æœæ’åºæŒ‡å®š
            note_type: æœç´¢çš„ç¬”è®°ç±»å‹

        Returns:

        """
        uri = "/api/sns/web/v1/search/notes"
        data = {
            "keyword": keyword,
            "page": page,
            "page_size": page_size,
            "search_id": search_id,
            "sort": sort.value,
            "note_type": note_type.value,
        }
        return await self.post(uri, data)

    async def get_note_by_id(
        self,
        note_id: str,
        xsec_source: str,
        xsec_token: str,
    ) -> Dict:
        """
        è·å–ç¬”è®°è¯¦æƒ…API
        Args:
            note_id:ç¬”è®°ID
            xsec_source: æ¸ é“æ¥æº
            xsec_token: æœç´¢å…³é”®å­—ä¹‹åè¿”å›çš„æ¯”è¾ƒåˆ—è¡¨ä¸­è¿”å›çš„token

        Returns:

        """
        if xsec_source == "":
            xsec_source = "pc_search"

        data = {
            "source_note_id": note_id,
            "image_formats": ["jpg", "webp", "avif"],
            "extra": {"need_body_topic": 1},
            "xsec_source": xsec_source,
            "xsec_token": xsec_token,
        }
        uri = "/api/sns/web/v1/feed"
        res = await self.post(uri, data)
        if res and res.get("items"):
            res_dict: Dict = res["items"][0]["note_card"]
            return res_dict
        # çˆ¬å–é¢‘ç¹äº†å¯èƒ½ä¼šå‡ºç°æœ‰çš„ç¬”è®°èƒ½æœ‰ç»“æœæœ‰çš„æ²¡æœ‰
        utils.logger.error(
            f"[XiaoHongShuClient.get_note_by_id] get note id:{note_id} empty and res:{res}"
        )
        return dict()

    async def get_note_comments(
        self,
        note_id: str,
        xsec_token: str,
        cursor: str = "",
    ) -> Dict:
        """
        è·å–ä¸€çº§è¯„è®ºçš„API
        Args:
            note_id: ç¬”è®°ID
            xsec_token: éªŒè¯token
            cursor: åˆ†é¡µæ¸¸æ ‡

        Returns:

        """
        uri = "/api/sns/web/v2/comment/page"
        params = {
            "note_id": note_id,
            "cursor": cursor,
            "top_comment_id": "",
            "image_formats": "jpg,webp,avif",
            "xsec_token": xsec_token,
        }
        return await self.get(uri, params)

    async def get_note_sub_comments(
        self,
        note_id: str,
        root_comment_id: str,
        xsec_token: str,
        num: int = 10,
        cursor: str = "",
    ):
        """
        è·å–æŒ‡å®šçˆ¶è¯„è®ºä¸‹çš„å­è¯„è®ºçš„API
        Args:
            note_id: å­è¯„è®ºçš„å¸–å­ID
            root_comment_id: æ ¹è¯„è®ºID
            xsec_token: éªŒè¯token
            num: åˆ†é¡µæ•°é‡
            cursor: åˆ†é¡µæ¸¸æ ‡

        Returns:

        """
        uri = "/api/sns/web/v2/comment/sub/page"
        params = {
            "note_id": note_id,
            "root_comment_id": root_comment_id,
            "num": num,
            "cursor": cursor,
            "image_formats": "jpg,webp,avif",
            "top_comment_id": "",
            "xsec_token": xsec_token,
        }
        return await self.get(uri, params)

    async def get_note_all_comments(
        self,
        note_id: str,
        xsec_token: str,
        crawl_interval: float = 1.0,
        callback: Optional[Callable] = None,
        max_count: int = 10,
    ) -> List[Dict]:
        """
        è·å–æŒ‡å®šç¬”è®°ä¸‹çš„æ‰€æœ‰ä¸€çº§è¯„è®ºï¼Œè¯¥æ–¹æ³•ä¼šä¸€ç›´æŸ¥æ‰¾ä¸€ä¸ªå¸–å­ä¸‹çš„æ‰€æœ‰è¯„è®ºä¿¡æ¯
        Args:
            note_id: ç¬”è®°ID
            xsec_token: éªŒè¯token
            crawl_interval: çˆ¬å–ä¸€æ¬¡ç¬”è®°çš„å»¶è¿Ÿå•ä½ï¼ˆç§’ï¼‰
            callback: ä¸€æ¬¡ç¬”è®°çˆ¬å–ç»“æŸå
            max_count: ä¸€æ¬¡ç¬”è®°çˆ¬å–çš„æœ€å¤§è¯„è®ºæ•°é‡
        Returns:

        """
        result = []
        comments_has_more = True
        comments_cursor = ""
        
        utils.logger.info(f"[XiaoHongShuClient.get_note_all_comments] ğŸ“ Note {note_id}: Starting to crawl comments (target: {max_count})")
        
        while comments_has_more and len(result) < max_count:
            comments_res = await self.get_note_comments(
                note_id=note_id, xsec_token=xsec_token, cursor=comments_cursor
            )
            comments_has_more = comments_res.get("has_more", False)
            comments_cursor = comments_res.get("cursor", "")
            if "comments" not in comments_res:
                utils.logger.info(
                    f"[XiaoHongShuClient.get_note_all_comments] No 'comments' key found in response: {comments_res}"
                )
                break
            comments = comments_res["comments"]
            if len(result) + len(comments) > max_count:
                comments = comments[: max_count - len(result)]
            if callback:
                await callback(note_id, comments)
            await asyncio.sleep(crawl_interval)
            result.extend(comments)
            
            # æ˜¾ç¤¾è¿›åº¦
            utils.logger.info(f"[XiaoHongShuClient.get_note_all_comments] ğŸ“ Note {note_id}: Crawled {len(result)}/{max_count} primary comments")
            sub_comments = await self.get_comments_all_sub_comments(
                comments=comments,
                xsec_token=xsec_token,
                crawl_interval=crawl_interval,
                callback=callback,
            )
            result.extend(sub_comments)
        
        utils.logger.info(f"[XiaoHongShuClient.get_note_all_comments] âœ… Note {note_id}: Finished crawling {len(result)} comments (primary + sub)")
        return result

    async def get_comments_all_sub_comments(
        self,
        comments: List[Dict],
        xsec_token: str,
        crawl_interval: float = 1.0,
        callback: Optional[Callable] = None,
    ) -> List[Dict]:
        """
        è·å–æŒ‡å®šä¸€çº§è¯„è®ºä¸‹çš„äºŒçº§è¯„è®º
        
        æ³¨æ„ï¼šå°çº¢ä¹¦é¡µé¢å±•å¼€è§„åˆ™
        - å¦‚æœäºŒçº§è¯„è®ºæ€»æ•° > 6æ¡ï¼Œç¬¬ä¸€æ¬¡ç‚¹å‡»"å±•å¼€å›å¤"ä¼šæ˜¾ç¤º6æ¡ï¼ˆåŸæœ¬1æ¡ + æ–°æ˜¾ç¤º5æ¡ï¼‰
        - å¦‚æœäºŒçº§è¯„è®ºæ€»æ•° â‰¤ 6æ¡ï¼Œç¬¬ä¸€æ¬¡ç‚¹å‡»"å±•å¼€å›å¤"ä¼šæ˜¾ç¤ºå…¨éƒ¨
        - å»ºè®®è®¾ç½® CRAWLER_MAX_SUB_COMMENTS_COUNT_PER_COMMENT = 6 æ¥æ¨¡æ‹Ÿç¬¬ä¸€æ¬¡å±•å¼€çš„æ•ˆæœ
        
        Args:
            comments: è¯„è®ºåˆ—è¡¨
            xsec_token: éªŒè¯token
            crawl_interval: çˆ¬å–ä¸€æ¬¡è¯„è®ºçš„å»¶è¿Ÿå•ä½ï¼ˆç§’ï¼‰
            callback: ä¸€æ¬¡è¯„è®ºçˆ¬å–ç»“æŸå

        Returns:
            äºŒçº§è¯„è®ºåˆ—è¡¨
        """
        if not config.ENABLE_GET_SUB_COMMENTS:
            utils.logger.info(
                f"[XiaoHongShuCrawler.get_comments_all_sub_comments] Crawling sub_comment mode is not enabled"
            )
            return []

        result = []
        for comment in comments:
            note_id = comment.get("note_id")
            sub_comments = comment.get("sub_comments")
            
            # ç»Ÿè®¡å½“å‰ä¸€çº§è¯„è®ºä¸‹å·²çˆ¬å–çš„äºŒçº§è¯„è®ºæ•°é‡
            sub_comments_count = 0
            max_sub_comments = config.CRAWLER_MAX_SUB_COMMENTS_COUNT_PER_COMMENT
            
            if sub_comments and callback:
                await callback(note_id, sub_comments)
                sub_comments_count += len(sub_comments)

            sub_comment_has_more = comment.get("sub_comment_has_more")
            if not sub_comment_has_more:
                continue

            root_comment_id = comment.get("id")
            sub_comment_cursor = comment.get("sub_comment_cursor")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦é™åˆ¶æ•°é‡ (0è¡¨ç¤ºä¸é™åˆ¶)
            while sub_comment_has_more:
                # å¦‚æœè®¾ç½®äº†é™åˆ¶ä¸”å·²è¾¾åˆ°é™åˆ¶ï¼Œåˆ™åœæ­¢çˆ¬å–
                if max_sub_comments > 0 and sub_comments_count >= max_sub_comments:
                    utils.logger.info(
                        f"[XiaoHongShuClient.get_comments_all_sub_comments] Reached sub-comment limit ({max_sub_comments}) for comment {root_comment_id}"
                    )
                    break
                
                try:
                    comments_res = await self.get_note_sub_comments(
                        note_id=note_id,
                        root_comment_id=root_comment_id,
                        xsec_token=xsec_token,
                        num=10,
                        cursor=sub_comment_cursor,
                    )
                except Exception as e:
                    utils.logger.error(
                        f"[XiaoHongShuClient.get_comments_all_sub_comments] Failed to get sub-comments for {root_comment_id}: {e}"
                    )
                    # è·å–äºŒçº§è¯„è®ºå¤±è´¥æ—¶ï¼Œè·³è¿‡è¿™ä¸ªè¯„è®ºï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª
                    break

                if comments_res is None:
                    utils.logger.info(
                        f"[XiaoHongShuClient.get_comments_all_sub_comments] No response found for note_id: {note_id}"
                    )
                    continue
                sub_comment_has_more = comments_res.get("has_more", False)
                sub_comment_cursor = comments_res.get("cursor", "")
                if "comments" not in comments_res:
                    utils.logger.info(
                        f"[XiaoHongShuClient.get_comments_all_sub_comments] No 'comments' key found in response: {comments_res}"
                    )
                    break
                comments = comments_res["comments"]
                
                # å¦‚æœè®¾ç½®äº†é™åˆ¶ï¼Œåªå–éœ€è¦çš„æ•°é‡
                if max_sub_comments > 0:
                    remaining = max_sub_comments - sub_comments_count
                    comments = comments[:remaining]
                
                if callback:
                    await callback(note_id, comments)
                await asyncio.sleep(crawl_interval)
                result.extend(comments)
                sub_comments_count += len(comments)
        return result

    async def screenshot_comment_element(
        self,
        note_id: str,
        comment_id: str,
        include_sub_comments: bool = True,
    ) -> Optional[str]:
        """
        å¯¹è¯„è®ºå…ƒç´ è¿›è¡Œæˆªå›¾ï¼ˆæ”¯æŒæˆªå–ä¸€çº§è¯„è®ºåŠå…¶äºŒçº§è¯„è®ºï¼‰
        
        Args:
            note_id: ç¬”è®°ID
            comment_id: è¯„è®ºID
            include_sub_comments: æ˜¯å¦åŒ…å«äºŒçº§è¯„è®ºåŒºåŸŸï¼ˆTrue=æˆªå–æ•´ä¸ªè¯„è®ºåŒºï¼ŒFalse=åªæˆªå–ä¸€çº§è¯„è®ºæœ¬èº«ï¼‰
            
        Returns:
            æˆªå›¾ä¿å­˜è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not config.ENABLE_GET_COMMENTS_SCREENSHOT:
            return None
            
        try:
            # æ„å»ºç¬”è®°URL
            note_url = f"https://www.xiaohongshu.com/explore/{note_id}"
            
            # å¦‚æœå½“å‰é¡µé¢ä¸æ˜¯ç›®æ ‡ç¬”è®°é¡µé¢ï¼Œåˆ™å¯¼èˆªåˆ°è¯¥é¡µé¢
            current_url = self.playwright_page.url
            if note_id not in current_url:
                utils.logger.info(f"[screenshot_comment_element] Navigating to note page: {note_url}")
                await self.playwright_page.goto(note_url, wait_until="networkidle", timeout=30000)
                await asyncio.sleep(2)
            
            # ç­‰å¾…è¯„è®ºåŒºåŠ è½½
            await self.playwright_page.wait_for_selector('[class*="comment"]', timeout=10000)
            
            # å°è¯•å¤šç§é€‰æ‹©å™¨æ¥å®šä½è¯„è®ºå…ƒç´ 
            comment_selectors = [
                f'[data-id="{comment_id}"]',
                f'[id*="{comment_id}"]',
                f'[data-comment-id="{comment_id}"]',
            ]
            
            comment_element = None
            for selector in comment_selectors:
                try:
                    locator = self.playwright_page.locator(selector).first
                    if await locator.count() > 0:
                        comment_element = locator
                        utils.logger.info(f"[screenshot_comment_element] Found comment with selector: {selector}")
                        break
                except Exception:
                    continue
            
            # å¦‚æœé€šè¿‡dataå±æ€§æ‰¾ä¸åˆ°ï¼Œå°è¯•é€šè¿‡æ–‡æœ¬å†…å®¹æŸ¥æ‰¾
            if not comment_element:
                utils.logger.warning(f"[screenshot_comment_element] Cannot find comment element by ID, trying alternative method")
                # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…éœ€è¦æ·»åŠ æ›´å¤šæŸ¥æ‰¾é€»è¾‘
                return None
            
            # æ»šåŠ¨åˆ°è¯„è®ºå…ƒç´ å¯è§
            await comment_element.scroll_into_view_if_needed()
            await asyncio.sleep(0.5)
            
            # åˆ›å»ºæˆªå›¾ä¿å­˜ç›®å½•
            screenshot_dir = os.path.join("data", "xhs", "screenshots", note_id)
            os.makedirs(screenshot_dir, exist_ok=True)
            
            # ç”Ÿæˆæˆªå›¾æ–‡ä»¶å
            timestamp = utils.get_current_timestamp()
            screenshot_filename = f"comment_{comment_id}_{timestamp}.png"
            if include_sub_comments:
                screenshot_filename = f"comment_with_replies_{comment_id}_{timestamp}.png"
            
            screenshot_path = os.path.join(screenshot_dir, screenshot_filename)
            
            # æˆªå›¾
            await comment_element.screenshot(path=screenshot_path, timeout=10000)
            
            utils.logger.info(f"[screenshot_comment_element] Screenshot saved: {screenshot_path}")
            return screenshot_path
            
        except Exception as e:
            utils.logger.error(f"[screenshot_comment_element] Error taking screenshot for comment {comment_id}: {e}")
            return None

    async def screenshot_comments_section(
        self,
        note_id: str,
        note_url: str = None,
    ) -> Optional[str]:
        """
        å¯¹æ•´ä¸ªè¯„è®ºåŒºè¿›è¡Œé•¿æˆªå›¾ï¼ˆåŒ…å«ä¸€çº§è¯„è®ºå’Œå±•å¼€åçš„äºŒçº§è¯„è®ºï¼‰
        
        Args:
            note_id: ç¬”è®°ID
            note_url: ç¬”è®°URLï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨æ„å»ºï¼‰
            
        Returns:
            æˆªå›¾ä¿å­˜è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not config.ENABLE_GET_COMMENTS_SCREENSHOT:
            utils.logger.info("[screenshot_comments_section] Comment screenshot is not enabled")
            return None
        
        # è·å–è¦æˆªå›¾çš„è¯„è®ºæ•°é‡é…ç½®
        screenshot_count = config.SCREENSHOT_COMMENTS_COUNT
        
        try:
            # æ„å»ºç¬”è®°URL
            if not note_url:
                note_url = f"https://www.xiaohongshu.com/explore/{note_id}"
            
            utils.logger.info(f"[screenshot_comments_section] Starting to screenshot comment section for note: {note_id}")
            utils.logger.info(f"[screenshot_comments_section] Target URL: {note_url}")
            
            # æ£€æŸ¥å½“å‰é¡µé¢URLï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦å¯¼èˆª
            try:
                current_url = self.playwright_page.url
                utils.logger.info(f"[screenshot_comments_section] Current URL: {current_url}")
                # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨ç›®æ ‡ç¬”è®°é¡µé¢ï¼ˆå®Œæ•´åŒ¹é…ï¼‰
                need_navigate = f"/explore/{note_id}" not in current_url
            except:
                current_url = ""
                need_navigate = True
            
            # å¯¼èˆªåˆ°ç¬”è®°è¯¦æƒ…é¡µ
            if need_navigate:
                utils.logger.info(f"[screenshot_comments_section] Navigating to note page: {note_url}")
                try:
                    await self.playwright_page.goto(note_url, wait_until="load", timeout=60000)
                    await asyncio.sleep(3)  # ç­‰å¾…é¡µé¢ç¨³å®š
                    utils.logger.info(f"[screenshot_comments_section] Navigation successful")
                except Exception as e:
                    utils.logger.error(f"[screenshot_comments_section] Navigation failed: {e}")
                    return None
            else:
                utils.logger.info(f"[screenshot_comments_section] Already on target note page, no navigation needed")
                await asyncio.sleep(1)
            
            # å…ˆæ»šåŠ¨é¡µé¢ï¼Œè®©è¯„è®ºåŒºåŠ è½½å‡ºæ¥
            utils.logger.info("[screenshot_comments_section] Scrolling down to load comments...")
            for i in range(3):
                await self.playwright_page.evaluate("window.scrollBy(0, window.innerHeight)")
                await asyncio.sleep(1)
            
            # ç­‰å¾…è¯„è®ºåŒºåŠ è½½ï¼Œå°è¯•å¤šç§é€‰æ‹©å™¨
            utils.logger.info("[screenshot_comments_section] Waiting for comment section to load...")
            comment_loaded = False
            comment_selectors_to_try = [
                '[class*="comment"]',
                '[class*="Comment"]',
                '[id*="comment"]',
                'text=å…¨éƒ¨è¯„è®º',
                'text=è¯„è®º',
            ]
            
            for selector in comment_selectors_to_try:
                try:
                    await self.playwright_page.wait_for_selector(selector, timeout=5000)
                    utils.logger.info(f"[screenshot_comments_section] Comment section found with selector: {selector}")
                    comment_loaded = True
                    break
                except Exception:
                    continue
            
            if not comment_loaded:
                utils.logger.warning(f"[screenshot_comments_section] Comment section not found after trying all selectors")
                # å°è¯•æˆªå›¾æ•´ä¸ªé¡µé¢çœ‹çœ‹
                try:
                    screenshot_dir = os.path.join("data", "xhs", "screenshots")
                    os.makedirs(screenshot_dir, exist_ok=True)
                    debug_path = os.path.join(screenshot_dir, f"debug_{note_id}.png")
                    await self.playwright_page.screenshot(path=debug_path)
                    utils.logger.info(f"[screenshot_comments_section] Saved debug screenshot: {debug_path}")
                except:
                    pass
                return None
            
            # æ»šåŠ¨åˆ°è¯„è®ºåŒº
            utils.logger.info("[screenshot_comments_section] Scrolling to comment section...")
            try:
                # å°è¯•å¤šç§è¯„è®ºåŒºå®¹å™¨é€‰æ‹©å™¨
                comment_container_selectors = [
                    '[class*="comment-container"]',
                    '[class*="comments"]',
                    '[class*="comment-section"]',
                    '[id*="comment"]',
                ]
                
                comment_container = None
                for selector in comment_container_selectors:
                    try:
                        locator = self.playwright_page.locator(selector).first
                        if await locator.count() > 0:
                            comment_container = locator
                            await comment_container.scroll_into_view_if_needed()
                            utils.logger.info(f"[screenshot_comments_section] Found comment container with selector: {selector}")
                            break
                    except Exception:
                        continue
                
                # å¦‚æœæ‰¾ä¸åˆ°å®¹å™¨ï¼Œå°±æ»šåŠ¨åˆ°ç¬¬ä¸€ä¸ªè¯„è®ºå…ƒç´ 
                if not comment_container:
                    comment_selectors = ['[class*="comment-item"]', '[class*="CommentItem"]']
                    for selector in comment_selectors:
                        try:
                            first_comment = self.playwright_page.locator(selector).first
                            if await first_comment.count() > 0:
                                await first_comment.scroll_into_view_if_needed()
                                comment_container = first_comment
                                break
                        except Exception:
                            continue
                
                if not comment_container:
                    utils.logger.warning("[screenshot_comments_section] Cannot find comment section")
                    return None
                    
            except Exception as e:
                utils.logger.warning(f"[screenshot_comments_section] Error scrolling to comments: {e}")
            
            await asyncio.sleep(1)
            
            # å°çº¢ä¹¦ä½¿ç”¨æ‡’åŠ è½½æœºåˆ¶ï¼šæ»šåŠ¨åˆ°åº•éƒ¨ä¼šè‡ªåŠ¨åŠ è½½ä¸‹ä¸€æ‰¹10æ¡è¯„è®º
            utils.logger.info("[screenshot_comments_section] ğŸ“œ Loading comments using scroll-based lazy loading...")
            
            # æ ¹æ®ç›®æ ‡è¯„è®ºæ•°é‡è®¡ç®—éœ€è¦æ»šåŠ¨çš„æ¬¡æ•°
            max_scroll_attempts = max(3, (screenshot_count + 9) // 10) if screenshot_count > 0 else 3
            utils.logger.info(f"[screenshot_comments_section] ğŸ“œ Target: {screenshot_count} comments, will scroll up to {max_scroll_attempts} times")
            
            scroll_attempts = 0
            last_comment_count = 0
            no_change_count = 0
            
            while scroll_attempts < max_scroll_attempts:
                # æ£€æŸ¥å½“å‰è¯„è®ºæ•°é‡
                try:
                    current_count = await self.playwright_page.locator('.parent-comment').count()
                    utils.logger.info(f"[screenshot_comments_section] ğŸ“Š Current: {current_count} comments (target: {screenshot_count})")
                    
                    # å¦‚æœå·²ç»è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œåœæ­¢æ»šåŠ¨
                    if current_count >= screenshot_count:
                        utils.logger.info(f"[screenshot_comments_section] âœ… Loaded enough comments ({current_count} >= {screenshot_count})")
                        break
                    
                    # å¦‚æœè¯„è®ºæ•°é‡æ²¡æœ‰å˜åŒ–ï¼Œè®°å½•æ¬¡æ•°
                    if current_count == last_comment_count:
                        no_change_count += 1
                        if no_change_count >= 2:
                            utils.logger.warning(f"[screenshot_comments_section] âš ï¸  Comment count not changing, stopping (may have fewer comments)")
                            break
                    else:
                        no_change_count = 0
                        last_comment_count = current_count
                    
                except Exception as e:
                    utils.logger.warning(f"[screenshot_comments_section] Error checking comment count: {e}")
                
                # æ»šåŠ¨åˆ°è¯„è®ºåŒºåº•éƒ¨ï¼Œè§¦å‘æ‡’åŠ è½½
                try:
                    utils.logger.info(f"[screenshot_comments_section] ğŸ“œ Scrolling to load more (attempt {scroll_attempts + 1}/{max_scroll_attempts})")
                    
                    # æ‰¾åˆ°æœ€åä¸€ä¸ªè¯„è®ºå…ƒç´ å¹¶æ»šåŠ¨åˆ°å®ƒ
                    last_comment = self.playwright_page.locator('.parent-comment').last
                    if await last_comment.count() > 0:
                        await last_comment.scroll_into_view_if_needed()
                        await asyncio.sleep(0.5)
                        
                        # å†å¾€ä¸‹æ»šåŠ¨ä¸€ç‚¹ï¼Œç¡®ä¿è§¦å‘æ‡’åŠ è½½
                        await self.playwright_page.evaluate("window.scrollBy(0, 500)")
                        await asyncio.sleep(1.5)  # ç­‰å¾…åŠ è½½
                    else:
                        # å¦‚æœæ‰¾ä¸åˆ°è¯„è®ºå…ƒç´ ï¼Œç›´æ¥æ»šåŠ¨åˆ°åº•éƒ¨
                        await self.playwright_page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                        await asyncio.sleep(1.5)
                    
                    scroll_attempts += 1
                    
                except Exception as e:
                    utils.logger.warning(f"[screenshot_comments_section] Error scrolling: {e}")
                    scroll_attempts += 1
            
            # æœ€ç»ˆæ£€æŸ¥
            try:
                final_count = await self.playwright_page.locator('.parent-comment').count()
                utils.logger.info(f"[screenshot_comments_section] ğŸ“Š Final: {final_count} comments loaded (target was {screenshot_count})")
                
                if final_count < screenshot_count:
                    utils.logger.warning(f"[screenshot_comments_section] âš ï¸  Only loaded {final_count}/{screenshot_count} comments")
            except:
                pass
            
            # ç­‰å¾…è¯„è®ºåŠ è½½å®Œæˆ
            await asyncio.sleep(1)
            
            # ========== æ–°å¢ï¼šé€å±‚æˆªå›¾å¹¶æ‹¼æ¥æˆé•¿å›¾ ==========
            utils.logger.info(f"[screenshot_comments_section] Starting layer-by-layer screenshot (target: {screenshot_count if screenshot_count > 0 else 'all'} comments)...")
            
            # åˆ›å»ºæˆªå›¾ä¿å­˜ç›®å½•ï¼ˆæŒ‰ç¬”è®°IDéš”ç¦»ï¼‰
            screenshot_dir = os.path.join("data", "xhs", "screenshots")
            temp_dir = os.path.join(screenshot_dir, "temp", note_id)  # æ¯ä¸ªç¬”è®°ç‹¬ç«‹ç›®å½•
            os.makedirs(temp_dir, exist_ok=True)
            
            # æ¸…ç†è¯¥ç¬”è®°çš„æ—§ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if os.path.exists(temp_dir):
                for old_file in os.listdir(temp_dir):
                    if old_file.startswith('layer_') and old_file.endswith('.png'):
                        try:
                            os.remove(os.path.join(temp_dir, old_file))
                        except:
                            pass
            
            # æŸ¥æ‰¾æ‰€æœ‰çˆ¶è¯„è®ºï¼ˆæ¯ä¸ªçˆ¶è¯„è®ºåŒ…å«1ä¸ªä¸€çº§è¯„è®º+å…¶æ‰€æœ‰äºŒçº§è¯„è®ºï¼‰
            # æ ¹æ®å°çº¢ä¹¦çš„HTMLç»“æ„ï¼Œä½¿ç”¨parent-commenté€‰æ‹©å™¨
            comment_selectors = [
                '#content-comments .parent-comment',  # ä»è¯„è®ºåŒºå®¹å™¨å†…æŸ¥æ‰¾
                '#detail-comment .parent-comment',  # å¦ä¸€ç§å¯èƒ½çš„å®¹å™¨ID
                'div[id*="comment"] .parent-comment',  # ä»ä»»ä½•è¯„è®ºå®¹å™¨å†…æŸ¥æ‰¾
                '.parent-comment',  # ç›´æ¥æŸ¥æ‰¾ï¼ˆå¯èƒ½ä¼šé€‰åˆ°å®¹å™¨ï¼‰
                '[class*="parent-comment"]',
                'div.parent-comment',
            ]
            
            comment_locator = None
            total_comments = 0
            for selector in comment_selectors:
                try:
                    locator = self.playwright_page.locator(selector)
                    count = await locator.count()
                    if count > 0:
                        # éªŒè¯é€‰åˆ°çš„æ˜¯çœŸæ­£çš„è¯„è®ºå…ƒç´ ï¼ˆåŒ…å«ç”¨æˆ·åã€å†…å®¹ç­‰ï¼‰
                        first_elem = locator.first
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯„è®ºçš„åŸºæœ¬å…ƒç´ ï¼ˆç”¨æˆ·ä¿¡æ¯ã€å†…å®¹ç­‰ï¼‰
                        text = await first_elem.inner_text()
                        if len(text) > 0:  # ç¡®ä¿æœ‰æ–‡æœ¬å†…å®¹
                            # æ£€æŸ¥ç¬¬ä¸€ä¸ªå…ƒç´ çš„é«˜åº¦ï¼Œå¦‚æœå¼‚å¸¸é«˜è¯´æ˜é€‰æ‹©å™¨æœ‰é—®é¢˜
                            first_box = await first_elem.bounding_box()
                            if first_box and first_box['height'] > 5000:
                                utils.logger.warning(f"[screenshot_comments_section] Selector {selector} first element height is {first_box['height']:.0f}px (abnormal!)")
                                utils.logger.warning(f"[screenshot_comments_section] This selector may be selecting a container instead of individual comments")
                                # å°è¯•ä¸‹ä¸€ä¸ªé€‰æ‹©å™¨
                                continue
                            
                            comment_locator = locator
                            total_comments = count
                            utils.logger.info(f"[screenshot_comments_section] Found {count} comments with selector: {selector}")
                            utils.logger.info(f"[screenshot_comments_section] First comment preview: {text[:50]}...")
                            if first_box:
                                utils.logger.info(f"[screenshot_comments_section] First comment height: {first_box['height']:.0f}px")
                            break
                except Exception as e:
                    utils.logger.debug(f"[screenshot_comments_section] Selector {selector} failed: {e}")
                    continue
            
            if not comment_locator or total_comments == 0:
                utils.logger.warning("[screenshot_comments_section] No comment elements found")
                # è¾“å‡ºé¡µé¢HTMLç»“æ„ç”¨äºè°ƒè¯•
                try:
                    page_content = await self.playwright_page.content()
                    debug_file = os.path.join(temp_dir, f"debug_page_{note_id}.html")
                    with open(debug_file, 'w', encoding='utf-8') as f:
                        f.write(page_content)
                    utils.logger.info(f"[screenshot_comments_section] Page HTML saved to {debug_file} for debugging")
                except:
                    pass
                return None
            
            # éªŒè¯æ‰¾åˆ°çš„çˆ¶è¯„è®ºå…ƒç´ å¹¶è¾“å‡ºè¯¦ç»†ä¿¡æ¯
            utils.logger.info(f"[screenshot_comments_section] Validating {total_comments} parent comment elements...")
            valid_comment_indices = []
            valid_comment_ids = []  # ä¿å­˜è¯„è®ºIDç”¨äºéªŒè¯
            
            for i in range(min(total_comments, 50)):  # æœ€å¤šæ£€æŸ¥å‰50ä¸ª
                try:
                    elem = comment_locator.nth(i)
                    # æŸ¥æ‰¾çˆ¶è¯„è®ºä¸­çš„ä¸€çº§è¯„è®ºï¼ˆä¸åŒ…å«comment-item-subï¼‰
                    primary_comment = elem.locator('.comment-item:not(.comment-item-sub)').first
                    if await primary_comment.count() > 0:
                        text = await primary_comment.inner_text()
                        if text and len(text.strip()) > 10:
                            # è·å–è¯„è®ºID
                            comment_id = await elem.evaluate("el => el.querySelector('.comment-item')?.id || ''")
                            
                            valid_comment_indices.append(i)
                            valid_comment_ids.append(comment_id)
                            
                            if len(valid_comment_indices) <= 3:  # åªæ˜¾ç¤ºå‰3ä¸ª
                                # æå–è¯„è®ºå†…å®¹ï¼ˆå»æ‰æ—¥æœŸã€ç‚¹èµæ•°ç­‰ï¼‰
                                content_lines = text.split('\n')
                                main_content = next((line for line in content_lines if len(line.strip()) > 10), text)
                                utils.logger.info(f"[screenshot_comments_section] Valid parent comment {len(valid_comment_indices)}: ID={comment_id}, Content={main_content[:60]}...")
                except:
                    continue
            
            utils.logger.info(f"[screenshot_comments_section] Found {len(valid_comment_indices)} valid parent comments out of {total_comments} elements")
            
            if len(valid_comment_indices) == 0:
                utils.logger.error("[screenshot_comments_section] No valid parent comment elements found")
                return None
            
            # é™åˆ¶æˆªå›¾çš„è¯„è®ºæ•°é‡
            target_count = min(screenshot_count if screenshot_count > 0 else len(valid_comment_indices), len(valid_comment_indices))
            
            # è¯¦ç»†æ—¥å¿—
            utils.logger.info(f"[screenshot_comments_section] Screenshot configuration:")
            utils.logger.info(f"  - Config target: {screenshot_count}")
            utils.logger.info(f"  - Valid comments found: {len(valid_comment_indices)}")
            utils.logger.info(f"  - Final target: {target_count}")
            
            if target_count < screenshot_count:
                utils.logger.warning(f"[screenshot_comments_section] âš ï¸  Only found {len(valid_comment_indices)} valid comments, less than target {screenshot_count}")
                utils.logger.warning(f"[screenshot_comments_section] âš ï¸  Will only screenshot {target_count} layers")
            
            utils.logger.info(f"[screenshot_comments_section] Will screenshot {target_count} parent comments (each with primary + sub-comments, layer by layer)")
            
            # é€å±‚æˆªå›¾
            layer_screenshots = []
            timestamp = utils.get_current_timestamp()
            successful_screenshots = 0
            
            # éšè—æ‰€æœ‰äº’åŠ¨æ ï¼ˆinteractionsï¼‰ï¼Œå‡å°‘ç©ºç™½å’Œä¸å¿…è¦çš„å†…å®¹
            try:
                await self.playwright_page.evaluate("""
                    // éšè—æ‰€æœ‰è¯„è®ºçš„äº’åŠ¨æ ï¼ˆç‚¹èµã€è¯„è®ºç­‰ï¼‰
                    const interactions = document.querySelectorAll('.interactions, .info .interactions');
                    interactions.forEach(bar => {
                        bar.style.display = 'none';
                    });
                    
                    // å‡å°‘è¯„è®ºä¹‹é—´çš„é—´è·
                    const comments = document.querySelectorAll('.parent-comment');
                    comments.forEach(comment => {
                        comment.style.marginBottom = '5px';
                        comment.style.paddingBottom = '0px';
                    });
                    
                    // å‡å°‘ä¸€çº§è¯„è®ºå’ŒäºŒçº§è¯„è®ºä¹‹é—´çš„é—´è·
                    const replyCont = document.querySelectorAll('.reply-container');
                    replyCont.forEach(container => {
                        container.style.marginTop = '5px';
                        container.style.paddingTop = '0px';
                    });
                """)
                utils.logger.info("[screenshot_comments_section] Hidden interactions and reduced spacing")
                await asyncio.sleep(0.5)
            except Exception as e:
                utils.logger.warning(f"[screenshot_comments_section] Failed to hide interactions: {e}")
            
            # åªå¤„ç†éªŒè¯è¿‡çš„æœ‰æ•ˆçˆ¶è¯„è®º
            for idx, comment_idx in enumerate(valid_comment_indices[:target_count]):
                try:
                    comment_element = comment_locator.nth(comment_idx)
                    expected_comment_id = valid_comment_ids[idx] if idx < len(valid_comment_ids) else "unknown"
                    
                    # è·å–çˆ¶è¯„è®ºçš„ä¸€çº§è¯„è®ºæ–‡æœ¬ç”¨äºæ—¥å¿—ï¼Œå¹¶éªŒè¯å…ƒç´ æ˜¯å¦æ­£ç¡®
                    try:
                        # è·å–è¯„è®ºIDç”¨äºç¡®è®¤
                        actual_comment_id = await comment_element.evaluate("el => el.querySelector('.comment-item')?.id || 'no-id'")
                        
                        primary_comment = comment_element.locator('.comment-item:not(.comment-item-sub)').first
                        primary_text = await primary_comment.inner_text()
                        content_lines = primary_text.split('\n')
                        main_content = next((line for line in content_lines if len(line.strip()) > 10), primary_text)
                        
                        # ç®€æ´æ—¥å¿—ï¼šåªæ˜¾ç¤ºç¬”è®°IDã€å±‚æ•°å’Œå†…å®¹æ‘˜è¦
                        utils.logger.info(f"[screenshot_comments_section] ğŸ“¸ Note {note_id}: Layer {successful_screenshots+1}/{target_count} - {main_content[:50]}...")
                        
                        # éªŒè¯IDæ˜¯å¦åŒ¹é…
                        if expected_comment_id and actual_comment_id != expected_comment_id:
                            utils.logger.warning(f"[screenshot_comments_section] WARNING: Comment ID mismatch! Expected {expected_comment_id}, got {actual_comment_id}")
                    except Exception as e:
                        utils.logger.warning(f"[screenshot_comments_section] Failed to get comment info for index {comment_idx}: {e}")
                        pass
                    
                    # ç»Ÿä¸€æ»šåŠ¨ç­–ç•¥ï¼šæ‰€æœ‰å±‚éƒ½ä½¿ç”¨ç›¸åŒçš„æ–¹å¼
                    await comment_element.scroll_into_view_if_needed()
                    await asyncio.sleep(1.0)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œè®©è¯„è®ºå†…å®¹å®Œå…¨åŠ è½½
                    
                    # å±•å¼€è¯¥çˆ¶è¯„è®ºçš„äºŒçº§è¯„è®ºï¼ˆæ¯ä¸ªä¸€çº§è¯„è®ºåªç‚¹å‡»ä¸€æ¬¡å±•å¼€æŒ‰é’®ï¼‰
                    try:
                        # ç»Ÿè®¡å±•å¼€å‰çš„äºŒçº§è¯„è®ºæ•°é‡
                        sub_comments_before = comment_element.locator('.comment-item-sub')
                        sub_count_before = await sub_comments_before.count()
                        
                        # æŸ¥æ‰¾"å±•å¼€å›å¤"æŒ‰é’®ï¼ˆåªåœ¨å½“å‰è¯„è®ºå…ƒç´ å†…æŸ¥æ‰¾ï¼‰
                        # ä½¿ç”¨classé€‰æ‹©å™¨æœ€å¯é ï¼Œé¿å…åŒ¹é…åˆ°å…¶ä»–è¯„è®ºçš„æŒ‰é’®
                        show_more_selectors = [
                            '.show-more',           # æœ€ç²¾ç¡®çš„classé€‰æ‹©å™¨
                            '[class*="show-more"]', # æ¨¡ç³ŠåŒ¹é…
                        ]
                        
                        button_clicked = False
                        for selector in show_more_selectors:
                            # å¦‚æœå·²ç»ç‚¹å‡»è¿‡æŒ‰é’®ï¼Œç›´æ¥è·³å‡ºå¾ªç¯
                            if button_clicked:
                                break
                            
                            try:
                                # åœ¨å½“å‰è¯„è®ºå…ƒç´ å†…æŸ¥æ‰¾å±•å¼€æŒ‰é’®ï¼ˆé™å®šåœ¨comment_elementèŒƒå›´å†…ï¼‰
                                show_more_button = comment_element.locator(selector).first
                                button_count = await show_more_button.count()
                                
                                if button_count > 0:
                                    if await show_more_button.is_visible(timeout=500):
                                        button_text = await show_more_button.inner_text()
                                        utils.logger.info(f"[screenshot_comments_section] Layer {successful_screenshots+1}: Found expand button '{button_text}' (clicking ONCE only)")
                                        
                                        # ç‚¹å‡»æŒ‰é’®å±•å¼€äºŒçº§è¯„è®º
                                        await show_more_button.click()
                                        button_clicked = True  # æ ‡è®°å·²ç‚¹å‡»ï¼Œé˜²æ­¢é‡å¤ç‚¹å‡»
                                        await asyncio.sleep(2.5)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿äºŒçº§è¯„è®ºå®Œå…¨åŠ è½½
                                        
                                        # ç»Ÿè®¡å±•å¼€åçš„æ•°é‡
                                        sub_comments_after = comment_element.locator('.comment-item-sub')
                                        sub_count_after = await sub_comments_after.count()
                                        utils.logger.info(f"[screenshot_comments_section] Layer {successful_screenshots+1}: âœ“ Expanded from {sub_count_before} to {sub_count_after} sub-comments (clicked once)")
                                        
                                        # ç«‹å³é€€å‡ºå¾ªç¯ï¼Œç¡®ä¿åªç‚¹å‡»ä¸€æ¬¡
                                        break
                            except Exception as e:
                                utils.logger.debug(f"[screenshot_comments_section] Selector '{selector}' failed: {e}")
                                continue
                        
                        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å±•å¼€æŒ‰é’®
                        if not button_clicked:
                            if sub_count_before > 0:
                                utils.logger.info(f"[screenshot_comments_section] Layer {successful_screenshots+1}: No expand button found, already showing {sub_count_before} sub-comments")
                            else:
                                utils.logger.debug(f"[screenshot_comments_section] Layer {successful_screenshots+1}: No sub-comments to expand")
                    except Exception as e:
                        utils.logger.warning(f"[screenshot_comments_section] Error expanding sub-comments: {e}")
                    
                    # ç§»é™¤è¯¥å±‚å…ƒç´ çš„marginå’Œpaddingï¼Œè®©æˆªå›¾æ›´ç´§å‡‘
                    # å¯¹ç¬¬ä¸€å±‚åšç‰¹æ®Šå¤„ç†ï¼Œä½¿ç”¨clipæˆªå›¾å»é™¤é¡¶éƒ¨ç©ºç™½
                    is_first_layer = (successful_screenshots == 0)
                    
                    try:
                        if is_first_layer:
                            # ç¬¬ä¸€å±‚ï¼šæ‰¾åˆ°å®é™…å†…å®¹çš„èµ·å§‹ä½ç½®ï¼Œç§»é™¤ä¸Šæ–¹ç©ºç™½
                            await comment_element.evaluate("""
                                element => {
                                    element.style.margin = '0';
                                    element.style.padding = '10px';
                                    element.style.paddingTop = '0';  // ç¬¬ä¸€å±‚ä¸è¦é¡¶éƒ¨padding
                                }
                            """)
                        else:
                            # å…¶ä»–å±‚ï¼šæ­£å¸¸è®¾ç½®
                            await comment_element.evaluate("""
                                element => {
                                    element.style.margin = '0';
                                    element.style.padding = '10px';
                                }
                            """)
                    except Exception as e:
                        utils.logger.debug(f"[screenshot_comments_section] Failed to adjust element style: {e}")
                    
                    # ç­‰å¾…è¯„è®ºå†…å®¹ï¼ˆåŒ…æ‹¬å›¾ç‰‡ï¼‰å®Œå…¨åŠ è½½
                    await asyncio.sleep(0.5)
                    
                    # æˆªå–è¯¥å±‚è¯„è®ºï¼ˆåŒ…å«å±•å¼€çš„äºŒçº§è¯„è®ºï¼‰
                    successful_screenshots += 1
                    # æ–‡ä»¶ååŒ…å«ç¬”è®°IDï¼Œä¾¿äºè¯†åˆ«
                    layer_screenshot_path = os.path.join(temp_dir, f"layer_{successful_screenshots}_{note_id}.png")
                    
                    # ä½¿ç”¨å…ƒç´ çš„screenshotæ–¹æ³•
                    try:
                        # è·å–å…ƒç´ çš„è¾¹ç•Œæ¡†ä¿¡æ¯
                        box = await comment_element.bounding_box()
                        if box:
                            utils.logger.info(f"[screenshot_comments_section] Layer {successful_screenshots} bounding box: x={box['x']:.0f}, y={box['y']:.0f}, width={box['width']:.0f}, height={box['height']:.0f}")
                            
                            # å¦‚æœæ˜¯ç¬¬ä¸€å±‚ä¸”é«˜åº¦å¼‚å¸¸ï¼Œè¾“å‡ºè¯¦ç»†ç»“æ„ä¿¡æ¯
                            if is_first_layer and box['height'] > 5000:
                                utils.logger.warning(f"[screenshot_comments_section] First layer height is abnormally large: {box['height']:.0f}px")
                                # è·å–å…ƒç´ çš„HTMLç»“æ„ç”¨äºè°ƒè¯•
                                try:
                                    element_info = await comment_element.evaluate("""
                                        element => {
                                            return {
                                                tagName: element.tagName,
                                                className: element.className,
                                                childCount: element.children.length,
                                                innerHTML_preview: element.innerHTML.substring(0, 500),
                                                has_comment_item: !!element.querySelector('.comment-item'),
                                                has_reply_container: !!element.querySelector('.reply-container'),
                                                comment_items_count: element.querySelectorAll('.comment-item').length
                                            };
                                        }
                                    """)
                                    utils.logger.info(f"[screenshot_comments_section] First layer element info: {element_info}")
                                except Exception as e:
                                    utils.logger.debug(f"Failed to get element info: {e}")
                        
                        if is_first_layer:
                            # ç¬¬ä¸€å±‚ï¼šä½¿ç”¨clipå‚æ•°ï¼Œä»å®é™…å†…å®¹å¼€å§‹æˆªå›¾
                            # æŸ¥æ‰¾ç¬¬ä¸€ä¸ªçœŸæ­£çš„è¯„è®ºå…ƒç´ ï¼ˆ.comment-itemï¼‰çš„ä½ç½®
                            try:
                                # è·å–ç¬¬ä¸€ä¸ª .comment-item ç›¸å¯¹äº .parent-comment çš„åç§»
                                offset_info = await comment_element.evaluate("""
                                    element => {
                                        const firstCommentItem = element.querySelector('.comment-item:not(.comment-item-sub)');
                                        if (firstCommentItem) {
                                            const parentRect = element.getBoundingClientRect();
                                            const commentRect = firstCommentItem.getBoundingClientRect();
                                            
                                            // è¿›ä¸€æ­¥æŸ¥æ‰¾å¤´åƒå…ƒç´ ï¼Œç¡®ä¿ä»æœ€é¡¶éƒ¨çš„å¯è§å†…å®¹å¼€å§‹
                                            const avatar = firstCommentItem.querySelector('.avatar');
                                            let offset = commentRect.top - parentRect.top;
                                            
                                            if (avatar) {
                                                const avatarRect = avatar.getBoundingClientRect();
                                                offset = Math.min(offset, avatarRect.top - parentRect.top);
                                            }
                                            
                                            return {
                                                offset: offset,
                                                commentTop: commentRect.top - parentRect.top,
                                                avatarTop: avatar ? avatar.getBoundingClientRect().top - parentRect.top : null
                                            };
                                        }
                                        return { offset: 0, commentTop: 0, avatarTop: null };
                                    }
                                """)
                                
                                first_comment_offset = offset_info['offset']
                                utils.logger.info(f"[screenshot_comments_section] First layer offset detection - comment: {offset_info['commentTop']}px, avatar: {offset_info['avatarTop']}px, final offset: {first_comment_offset}px")
                                
                                if first_comment_offset > 5 and box:  # åªæœ‰å½“ç©ºç™½è¶…è¿‡5pxæ—¶æ‰è£å‰ª
                                    # ä½¿ç”¨page.screenshot + clipæ¥ç²¾ç¡®æˆªå–
                                    utils.logger.info(f"[screenshot_comments_section] First layer: clipping top {first_comment_offset:.0f}px to remove whitespace")
                                    clip = {
                                        'x': box['x'],
                                        'y': box['y'] + first_comment_offset,
                                        'width': box['width'],
                                        'height': box['height'] - first_comment_offset
                                    }
                                    await self.playwright_page.screenshot(path=layer_screenshot_path, clip=clip, timeout=10000)
                                else:
                                    utils.logger.info(f"[screenshot_comments_section] First layer: offset too small ({first_comment_offset:.0f}px), using normal screenshot")
                                    await comment_element.screenshot(path=layer_screenshot_path, timeout=10000)
                            except Exception as clip_error:
                                utils.logger.warning(f"[screenshot_comments_section] Clip screenshot failed: {clip_error}, using normal screenshot")
                                await comment_element.screenshot(path=layer_screenshot_path, timeout=10000)
                        else:
                            # å…¶ä»–å±‚ï¼šæ­£å¸¸æˆªå›¾
                            await comment_element.screenshot(path=layer_screenshot_path, timeout=10000)
                        
                        layer_screenshots.append(layer_screenshot_path)
                        utils.logger.info(f"[screenshot_comments_section] Layer {successful_screenshots}/{target_count} screenshot saved")
                    except Exception as screenshot_error:
                        utils.logger.error(f"[screenshot_comments_section] Failed to screenshot layer {successful_screenshots}: {screenshot_error}")
                        raise
                    
                except Exception as e:
                    utils.logger.warning(f"[screenshot_comments_section] Error screenshotting comment at index {comment_idx}: {e}")
                    continue
            
            if not layer_screenshots:
                utils.logger.error("[screenshot_comments_section] No layers were successfully screenshotted")
                return None
            
            utils.logger.info(f"[screenshot_comments_section] Successfully captured {len(layer_screenshots)} layers (target was {target_count}), now stitching...")
            
            # å¦‚æœæˆªå›¾æ•°é‡ä¸å¤Ÿï¼Œç»™å‡ºè­¦å‘Š
            if len(layer_screenshots) < target_count:
                utils.logger.warning(f"[screenshot_comments_section] Only captured {len(layer_screenshots)} layers, expected {target_count}. Page may not have enough comments.")
            
            # æ‹¼æ¥æ‰€æœ‰å±‚çš„æˆªå›¾æˆä¸€å¼ é•¿å›¾ï¼ˆä¸åšä»»ä½•è£å‰ªï¼‰
            screenshot_success = False
            try:
                images = [Image.open(path) for path in layer_screenshots]
                
                # ç›´æ¥ä½¿ç”¨åŸå§‹å›¾ç‰‡ï¼Œä¸åšä»»ä½•è£å‰ª
                utils.logger.info(f"[screenshot_comments_section] Using original images without cropping")
                
                # è®¡ç®—æ€»é«˜åº¦å’Œæœ€å¤§å®½åº¦
                total_height = sum(img.height for img in images)
                max_width = max(img.width for img in images)
                
                utils.logger.info(f"[screenshot_comments_section] Stitching {len(images)} images, total height: {total_height}px, max width: {max_width}px")
                
                # åˆ›å»ºæ–°çš„é•¿å›¾
                stitched_image = Image.new('RGB', (max_width, total_height), (255, 255, 255))
                
                # é€å±‚ç²˜è´´
                current_y = 0
                for idx, img in enumerate(images):
                    stitched_image.paste(img, (0, current_y))
                    utils.logger.info(f"[screenshot_comments_section] Pasted layer {idx+1} at y={current_y}, height={img.height}px")
                    current_y += img.height
                
                # ä¿å­˜æ‹¼æ¥åçš„é•¿å›¾
                screenshot_filename = f"comments_{note_id}_{timestamp}.png"
                screenshot_path = os.path.join(screenshot_dir, screenshot_filename)
                stitched_image.save(screenshot_path, 'PNG')
                screenshot_success = True
                utils.logger.info(f"[screenshot_comments_section] Stitched long image saved: {screenshot_path}")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for img in images:
                    img.close()
                
                # è°ƒè¯•æ¨¡å¼ï¼šä¿ç•™ä¸´æ—¶æ–‡ä»¶ä»¥ä¾¿æ£€æŸ¥
                # å¦‚æœä¸éœ€è¦è°ƒè¯•ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šå³å¯åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                # for path in layer_screenshots:
                #     try:
                #         os.remove(path)
                #     except:
                #         pass
                # utils.logger.info(f"[screenshot_comments_section] Temporary files cleaned up")
                
                utils.logger.info(f"[screenshot_comments_section] Temporary layer files kept in {temp_dir} for debugging")
                
            except Exception as e:
                utils.logger.error(f"[screenshot_comments_section] Error stitching images: {e}")
                import traceback
                traceback.print_exc()
                return None
            # ========== é€å±‚æˆªå›¾+æ‹¼æ¥ç»“æŸ ==========
            
            if not screenshot_success:
                utils.logger.error("[screenshot_comments_section] Screenshot stitching failed")
                return None
            
            if screenshot_success:
                utils.logger.info(f"[screenshot_comments_section] Screenshot saved: {screenshot_path}")
                return screenshot_path
            else:
                utils.logger.error("[screenshot_comments_section] Failed to take screenshot")
                return None
            
        except Exception as e:
            utils.logger.error(f"[screenshot_comments_section] Error: {e}")
            import traceback
            traceback.print_exc()
            return None

    async def get_creator_info(self, user_id: str) -> Dict:
        """
        é€šè¿‡è§£æç½‘é¡µç‰ˆçš„ç”¨æˆ·ä¸»é¡µHTMLï¼Œè·å–ç”¨æˆ·ä¸ªäººç®€è¦ä¿¡æ¯
        PCç«¯ç”¨æˆ·ä¸»é¡µçš„ç½‘é¡µå­˜åœ¨window.__INITIAL_STATE__è¿™ä¸ªå˜é‡ä¸Šçš„ï¼Œè§£æå®ƒå³å¯
        eg: https://www.xiaohongshu.com/user/profile/59d8cb33de5fb4696bf17217
        """
        uri = f"/user/profile/{user_id}"
        html_content = await self.request(
            "GET", self._domain + uri, return_response=True, headers=self.headers
        )
        return self._extractor.extract_creator_info_from_html(html_content)

    async def get_notes_by_creator(
        self,
        creator: str,
        cursor: str,
        page_size: int = 30,
    ) -> Dict:
        """
        è·å–åšä¸»çš„ç¬”è®°
        Args:
            creator: åšä¸»ID
            cursor: ä¸Šä¸€é¡µæœ€åä¸€æ¡ç¬”è®°çš„ID
            page_size: åˆ†é¡µæ•°æ®é•¿åº¦

        Returns:

        """
        uri = "/api/sns/web/v1/user_posted"
        data = {
            "user_id": creator,
            "cursor": cursor,
            "num": page_size,
            "image_formats": "jpg,webp,avif",
        }
        return await self.get(uri, data)

    async def get_all_notes_by_creator(
        self,
        user_id: str,
        crawl_interval: float = 1.0,
        callback: Optional[Callable] = None,
    ) -> List[Dict]:
        """
        è·å–æŒ‡å®šç”¨æˆ·ä¸‹çš„æ‰€æœ‰å‘è¿‡çš„å¸–å­ï¼Œè¯¥æ–¹æ³•ä¼šä¸€ç›´æŸ¥æ‰¾ä¸€ä¸ªç”¨æˆ·ä¸‹çš„æ‰€æœ‰å¸–å­ä¿¡æ¯
        Args:
            user_id: ç”¨æˆ·ID
            crawl_interval: çˆ¬å–ä¸€æ¬¡çš„å»¶è¿Ÿå•ä½ï¼ˆç§’ï¼‰
            callback: ä¸€æ¬¡åˆ†é¡µçˆ¬å–ç»“æŸåçš„æ›´æ–°å›è°ƒå‡½æ•°

        Returns:

        """
        result = []
        notes_has_more = True
        notes_cursor = ""
        while notes_has_more and len(result) < config.CRAWLER_MAX_NOTES_COUNT:
            notes_res = await self.get_notes_by_creator(user_id, notes_cursor)
            if not notes_res:
                utils.logger.error(
                    f"[XiaoHongShuClient.get_notes_by_creator] The current creator may have been banned by xhs, so they cannot access the data."
                )
                break

            notes_has_more = notes_res.get("has_more", False)
            notes_cursor = notes_res.get("cursor", "")
            if "notes" not in notes_res:
                utils.logger.info(
                    f"[XiaoHongShuClient.get_all_notes_by_creator] No 'notes' key found in response: {notes_res}"
                )
                break

            notes = notes_res["notes"]
            utils.logger.info(
                f"[XiaoHongShuClient.get_all_notes_by_creator] got user_id:{user_id} notes len : {len(notes)}"
            )

            remaining = config.CRAWLER_MAX_NOTES_COUNT - len(result)
            if remaining <= 0:
                break

            notes_to_add = notes[:remaining]
            if callback:
                await callback(notes_to_add)

            result.extend(notes_to_add)
            await asyncio.sleep(crawl_interval)

        utils.logger.info(
            f"[XiaoHongShuClient.get_all_notes_by_creator] Finished getting notes for user {user_id}, total: {len(result)}"
        )
        return result

    async def get_note_short_url(self, note_id: str) -> Dict:
        """
        è·å–ç¬”è®°çš„çŸ­é“¾æ¥
        Args:
            note_id: ç¬”è®°ID

        Returns:

        """
        uri = f"/api/sns/web/short_url"
        data = {"original_url": f"{self._domain}/discovery/item/{note_id}"}
        return await self.post(uri, data=data, return_response=True)

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(1))
    async def get_note_by_id_from_html(
        self,
        note_id: str,
        xsec_source: str,
        xsec_token: str,
        enable_cookie: bool = False,
    ) -> Optional[Dict]:
        """
        é€šè¿‡è§£æç½‘é¡µç‰ˆçš„ç¬”è®°è¯¦æƒ…é¡µHTMLï¼Œè·å–ç¬”è®°è¯¦æƒ…, è¯¥æ¥å£å¯èƒ½ä¼šå‡ºç°å¤±è´¥çš„æƒ…å†µï¼Œè¿™é‡Œå°è¯•é‡è¯•3æ¬¡
        copy from https://github.com/ReaJason/xhs/blob/eb1c5a0213f6fbb592f0a2897ee552847c69ea2d/xhs/core.py#L217-L259
        thanks for ReaJason
        Args:
            note_id:
            xsec_source:
            xsec_token:
            enable_cookie:

        Returns:

        """
        url = (
            "https://www.xiaohongshu.com/explore/"
            + note_id
            + f"?xsec_token={xsec_token}&xsec_source={xsec_source}"
        )
        copy_headers = self.headers.copy()
        if not enable_cookie:
            del copy_headers["Cookie"]

        html = await self.request(
            method="GET", url=url, return_response=True, headers=copy_headers
        )

        return self._extractor.extract_note_detail_from_html(note_id, html)