# 截图续爬功能说明

## 🎯 问题场景

在截图过程中中断会导致：

```
爬取评论：10条一级评论 ✅
爬取二级评论：完成 ✅
保存到 comments.csv ✅

开始截图：
  layer_1.png ✅
  layer_2.png ✅
  layer_3.png ✅
  【中断】❌

结果：
  - 评论数据完整（10条一级评论）
  - 截图不完整（只有3层临时文件）
  - 没有最终拼接的长图
```

---

## ✅ 解决方案：双重检查机制

### **判断标准（必须同时满足）**

```python
1. 一级评论数量 >= 10条  ✅
2. 截图文件存在          ✅

只有两个条件都满足，才认为已完成
```

---

## 🔄 中断后的行为

### **场景1：评论爬取时中断**

```
爬取笔记A：
  一级评论：1, 2, 3, 4, 5 【中断】
  
comments.csv: 5条一级评论 ⚠️
截图：无
```

**重新运行**：
```
检查：
  - 一级评论：5条 < 10条 ❌
  - 截图：无 ❌
    ↓
【清理】删除5条评论
【重新爬取】10条一级评论 + 二级评论
【重新截图】10层 → 拼接成长图 ✅
```

---

### **场景2：截图时中断（已修复）**

```
爬取笔记A：
  一级评论：10条 ✅
  二级评论：完成 ✅
  
comments.csv: 10条一级评论 ✅

开始截图：
  layer_1.png ✅
  layer_2.png ✅
  layer_3.png 【中断】❌
  
最终截图：无 ❌
```

**重新运行（新逻辑）**：
```
检查：
  - 一级评论：10条 >= 10条 ✅
  - 截图：不存在 ❌
    ↓
【判定】不完整，需要重新处理
【保留评论】不删除（因为评论已完整）
【重新爬取】重新爬取并截图
【生成截图】10层 → 拼接成长图 ✅
```

---

## 📊 日志示例

### **启动时的检查**

```
[CrawlProgressManager] Found 3 notes with complete comments but missing screenshots
  - These notes will be re-crawled to generate screenshots

[CrawlProgressManager] Comment crawl status:
  - Complete notes (>=10 primary comments + screenshot): 15
  - Incomplete notes (<10 primary comments): 2
    - note_001: 5 primary + 11 sub = 16 total
    - note_002: 7 primary + 18 sub = 25 total
```

**解读**：
- 15个笔记：评论完整 + 截图存在 ✅
- 3个笔记：评论完整但截图缺失 ⚠️（会重新爬取）
- 2个笔记：评论不完整 ⚠️（会清理并重新爬取）

---

## 🔍 截图检查逻辑

### **检查方式**

```python
# 检查截图文件是否存在（模糊匹配）
screenshot_dir = "data/xhs/screenshots"
for filename in os.listdir(screenshot_dir):
    if note_id in filename and filename.endswith('.png') and 'comments' in filename:
        screenshot_exists = True
        break
```

### **匹配规则**

截图文件名格式：`comments_{note_id}_{timestamp}.png`

例如：
- `comments_65e159e5_1729134000.png` ✅
- `comments_65e159e5_1729134123.png` ✅

只要包含：
- 笔记ID（`note_id`）
- `comments` 关键字
- `.png` 扩展名

就认为截图存在。

---

## ⚙️ 配置选项

### **config.py**

```python
# 启用评论截图功能
ENABLE_GET_COMMENTS_SCREENSHOT = True

# 启用断点续爬
ENABLE_RESUME_CRAWL = True

# 自动清理不完整的评论
ENABLE_AUTO_CLEAN_INCOMPLETE_COMMENTS = True
```

### **是否检查截图**

默认开启，如果不想检查截图（只检查评论数量），可以在代码中修改：

```python
# 在 core.py 中
self.progress_manager.load_crawled_comment_note_ids(
    min_comment_count=config.CRAWLER_MAX_COMMENTS_COUNT_SINGLENOTES,
    check_screenshot=False  # 设置为 False 关闭截图检查
)
```

---

## 📁 文件结构

```
data/xhs/
├── csv/
│   └── search_comments_2025-10-17.csv  # 评论数据
└── screenshots/
    ├── comments_note_001_timestamp.png  # 笔记1的截图 ✅
    ├── comments_note_002_timestamp.png  # 笔记2的截图 ✅
    ├── comments_note_003_timestamp.png  # 笔记3的截图 ✅（缺失会重新生成）
    └── temp/
        ├── layer_1_timestamp.png        # 临时文件
        ├── layer_2_timestamp.png
        └── ...
```

---

## 🎯 完整流程示例

### **第一次运行（截图时中断）**

```
爬取20个笔记：
  - 笔记1-15：评论完整 + 截图完成 ✅
  - 笔记16：评论完整，截图到第3层时【中断】❌
  - 笔记17-20：未爬取
```

**结果**：
- `comments.csv`：16个笔记的评论
- 截图：15个完整截图 + 笔记16的3个临时层文件

---

### **第二次运行（自动续爬）**

```
启动检查：
  - 笔记1-15：评论✅ + 截图✅ → 跳过
  - 笔记16：评论✅ + 截图❌ → 重新爬取
  - 笔记17-20：未爬取 → 正常爬取

处理笔记16：
  1. 检测到评论完整但截图缺失
  2. 不删除评论（保留已有数据）
  3. 重新爬取（会获取最新评论）
  4. 重新截图10层并拼接
  5. 生成完整截图 ✅

继续爬取笔记17-20 ✅
```

**最终结果**：
- `comments.csv`：20个笔记的评论 ✅
- 截图：20个完整截图 ✅

---

## 🚨 注意事项

### **1. 临时文件不影响检查**

临时文件（`temp/layer_*.png`）不会被识别为有效截图。

只有最终拼接的长图（`comments_{note_id}_{timestamp}.png`）才算有效。

### **2. 重新爬取会获取最新数据**

如果笔记的评论有更新（新增了评论），重新爬取时会获取最新的评论数据。

### **3. 旧截图不会被删除**

如果重新生成截图，旧的截图文件不会自动删除，会保留多个版本：
```
comments_note_001_1729134000.png  # 旧版本
comments_note_001_1729138000.png  # 新版本
```

如果需要，可以手动删除旧版本。

---

## ✅ 总结

**双重检查机制**：
```
完整标准 = 评论完整 + 截图存在

评论完整：一级评论数量 >= 10
截图存在：存在 comments_{note_id}_*.png 文件
```

**中断后的行为**：
- ✅ 评论不完整 → 清理并重新爬取
- ✅ 评论完整但截图缺失 → 重新爬取并截图
- ✅ 评论完整且截图存在 → 跳过

**配置**：
```python
ENABLE_GET_COMMENTS_SCREENSHOT = True  # 启用截图
ENABLE_RESUME_CRAWL = True             # 启用续爬
```

现在你可以放心爬取了！即使在截图过程中中断，下次运行也会自动检测并重新生成截图！🎉
